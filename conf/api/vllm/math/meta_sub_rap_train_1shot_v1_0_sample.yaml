defaults:
  - hydra: default
  - post_process: math
  - _self_

hydra:
  searchpath:
    - file://conf/

train_file:
dev_file:
#test_file: ../research.data/MetaMathQA/MetaMathQA-25K-sample.json
test_file: ../research.data/MetaMathQA/MetaMath-math-55k.json

save_best: False
exp_name:
exp_notes:
output_dir: ../pretrained-models/qwen-1.5-72b-chat
eval_sub_path:


split_size: 2
split_id: 0
port: 6000
sample_n: 5
temperature: 0.8
top_p: 0.8

#sampling_params:
#  _target_: vllm.SamplingParams
#  n: ${sample_n}
#  temperature: ${temperature}
#  max_tokens: 4096
#  stop: [ "<eos>", "\n\n\n\n", "### Instruction" ]
#  top_p: ${top_p}


read_tensor:
  _target_: data.logic_combine.ResponseAlignDataset
  aligner:
    _target_: data.input_aligner.concat_aligner
    aligners:
      - _target_: data.math.meta_math_gold_answer_extractor
        response_field: "response"
  template: "{instruction}\n\n{few_shot_prompt}\n\n### Question: {query}\n\nSubQuestion 1: "
  instruction: "Given a question, please decompose it into sub-questions. For each sub-question, please answer it in a complete sentence, ending with \"The answer is\". When the original question is answerable, please start the sub-question with \"Now we can answer the question: \"."
  few_shot_prompt:
    _target_: data.logiqav2.read_single_file
    file_path: data/prompts/meta_math/react_prompt_1.txt
  split_size: ${split_size}
  split_id: ${split_id}
  service_based: True
  service_processor:
    _target_: data.vllm.VLLMRequestGenerator
    api_url: http://0.0.0.0:${port}/v1/completions
    max_tokens: 3072
    model: qwen-1.5-72b
    stop: [ "</s>", "\n\n\n\n", "### Question", "<|im_end|>" ]
    n: ${sample_n}
    temperature: ${temperature}
    top_p: ${top_p}
  flush_file: ${flush_file}


suffix: n${sample_n}.tem${temperature}.p${top_p}.v1.0.${split_id}-of-${split_size}
#suffix: n${sample_n}.tem${temperature}.p${top_p}.v1.0
#output_file: api-outputs/qwen-1.5-72b/meta_math_sub.25k.rap.train.1shot.${suffix}.json
output_file: api-outputs/qwen-1.5-72b/meta_math_sub.math.55k.rap.train.1shot.${suffix}.json
flush_file: ${output_file}l

post_process:
  answer_clean:
    _target_: data.math.math_answer_cleaner
    separator: "The answer is"
  resume: True
  index_field: "id"
  label_field: "label"

# Dataloader
num_workers: 8
prefetch_factor:

# Training hyper-parameters
per_gpu_train_batch_size: 1
per_gpu_eval_batch_size: 1

ddp_eval: False
no_cuda: False
seed: 42
local_rank: -1

# Temporary variables
fp16: True
fp16_bfloat16: True
n_gpu: 1
device:
train_batch_size:
eval_batch_size:
world_size: