defaults:
  - hydra: default
  - reader/logiqav2@read_tensor: react_service_0shot_v1_0
  - post_process: openai_react
  - api/vllm/vllm_params@sampling_params: sampling_param_sample
  - _self_

hydra:
  searchpath:
    - file://conf/

train_file: ../research.data/LogiQA2.0/logiqa/DATA/LOGIQA/train.txt
dev_file: ../research.data/LogiQA2.0/logiqa/DATA/LOGIQA/dev.txt
test_file: ../research.data/LogiQA2.0/logiqa/DATA/LOGIQA/train.txt

save_best: False
exp_name:
exp_notes:
output_dir: experiments/${exp_name}

step: 800
eval_sub_path: checkpoint-${step}

read_tensor:
  split_size: 8
  split_id: 0
  template_id: 6
  service_based: False
  service_processor:

swap_space: 8

output_file: ${output_dir}/${eval_sub_path}/logiqav2-train.react.sample5.${read_tensor.split_id}-${read_tensor.split_size}.v1.0.0shot.json
flush_file: ${output_file}l

# Dataloader
num_workers: 48
prefetch_factor: 2

ddp_eval: True
no_cuda: False
seed: 42
local_rank: -1

# Temporary variables
fp16: True
fp16_bfloat16: True
n_gpu: 1
device:
train_batch_size:
eval_batch_size:
world_size:
